{"nbformat_minor": 2, "cells": [{"source": "# A sentiment(al) analysis of why Red Dwarf is no longer funny (to me)\n## Part II: How can the same smeg happen to the same show twice?", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "What follows is a continuation of the (faux) analysis of the humour in Red Dwarf and why it seems to be waning in recent series. The first part is constitutes a blog post and Jupyter notebook which can be found [here](http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarf) and [here](https://github.com/ibebbs/RedDwarfAnalysis/blob/master/Investigation.ipynb) respectively .\n\nIt uses the following packages:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "#load \"Paket.fsx\"\n\nPaket.Package [ \"FsLab\" ]", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 2, "cell_type": "code", "source": "#r \"packages/FSharp.Data/lib/net40/FSharp.Data.dll\"\n#r \"packages/Google.DataTable.Net.Wrapper/lib/Google.DataTable.Net.Wrapper.dll\"\n#r \"packages/XPlot.GoogleCharts/lib/net45/XPlot.GoogleCharts.dll\"\n#r \"packages/MathNet.Numerics/lib/net40/MathNet.Numerics.dll\"\n#r \"packages/MathNet.Numerics.FSharp/lib/net40/MathNet.Numerics.FSharp.dll\"\n\nopen System\nopen System.IO\nopen System.Text.RegularExpressions\nopen FSharp.Data\nopen FSharp.Data.JsonExtensions\nopen XPlot\nopen XPlot.GoogleCharts\nopen MathNet.Numerics.Statistics", "outputs": [], "metadata": {"collapsed": false}}, {"source": "And, despite my commit of the display printer below being [merged into the IfSharp package](https://github.com/fsprojects/IfSharp/issues/118#issuecomment-287387603) it seems it is still required. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": "open IfSharp.Kernel.App\n\n@\"<script src=\"\"https://www.google.com/jsapi\"\"><\/script>\" |> Util.Html |> Display\n\ntype XPlot.GoogleCharts.GoogleChart with\n  member __.GetContentHtml() =\n    let html = __.GetInlineHtml()\n    html\n      .Replace (\"google.setOnLoadCallback(drawChart);\", \"google.load('visualization', '1.0', { packages: ['corechart'], callback: drawChart })\")\n\ntype XPlot.GoogleCharts.Chart with\n  static member Content (chart : GoogleChart) =\n    { ContentType = \"text/html\"; Data = chart.GetContentHtml() }\n\nAddDisplayPrinter (fun (plot: XPlot.GoogleCharts.GoogleChart) -> { ContentType = \"text/html\"; Data = plot.GetContentHtml() })", "outputs": [{"output_type": "display_data", "data": {"text/html": "<script src=\"https://www.google.com/jsapi\"><\/script>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "## Observation\nIn the previous analysis, I posited that several of the latter series of Red Dwarf were no longer as funny as the firsth few series. I decided to use viewer ratings from various sites (but mainly IMDB) to see if most people agreed with this argument or if I had simply lost my ability to appreciate the humour.\n\nBy the end of the analysis I had found that, while there was a general deterioration in the viewer ratings for later series of Red Dwarf, the deterioration was nowhere near as pronounced as I imagined and therefore concluded that I must simply be a **miserable old git**. However, I also noted that [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) might provide further in sight into the deterioration of viewer ratings and, specifically, my impression of the later series.\n\nThis analysis endeavours to employ this approach to see if the general sentiment expressed within episodes of the show and/or by specific characters has changed and, if so, what effect this has had on viewer rating.", "cell_type": "markdown", "metadata": {}}, {"source": "## Information\nIn order to employ semantic analysis, we need to text of content of each episode, ideally attributed to each character. Fortunately, as Red Dwarf has such a dedicated fan base, it wasn't difficult to find 'transcripts' for each [episode of the show](http://www.ladyofthecake.com/reddwarf/html/scripts.html).\n\nThese were downloaded to a 'Transcripts' directory and the index of each episode updated to include the name of the transcript for the episode, as shown below:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 23, "cell_type": "code", "source": "type TranscriptFormat =\n| SameLine\n| NextLine\n| NextLineDoubleSpaced\n\ntype EpisodeSource = {\n    Id : string\n    Transcript : string option\n    Format : TranscriptFormat\n    Season : int\n    Episode : int\n}\n\nlet episodeSources = [\n    { Id = \"tt0684181\"; Transcript = Some \"Theend.txt\"; Format = SameLine; Season = 1; Episode = 1 };\n    { Id = \"tt0684157\"; Transcript = Some \"Futureec.txt\"; Format = SameLine; Season = 1; Episode = 2 };\n    { Id = \"tt0684145\"; Transcript = Some \"Balanceo.txt\"; Format = SameLine; Season = 1; Episode = 3 };\n    { Id = \"tt0684186\"; Transcript = Some \"Waitingf.txt\"; Format = SameLine; Season = 1; Episode = 4 };\n    { Id = \"tt0684151\"; Transcript = Some \"Confiden.txt\"; Format = SameLine; Season = 1; Episode = 5 };\n    { Id = \"tt0684165\"; Transcript = Some \"Me2.txt\"; Format = SameLine; Season = 1; Episode = 6 };\n    { Id = \"tt0684161\"; Transcript = Some \"Kryten.txt\"; Format = SameLine; Season = 2; Episode = 1 };\n    { Id = \"tt0684146\"; Transcript = Some \"Betterth.txt\"; Format = SameLine; Season = 2; Episode = 2 };\n    { Id = \"tt0684180\"; Transcript = Some \"Thanksfo.txt\"; Format = SameLine; Season = 2; Episode = 3 };\n    { Id = \"tt0684177\"; Transcript = Some \"Stasisle.txt\"; Format = SameLine; Season = 2; Episode = 4 };\n    { Id = \"tt0684175\"; Transcript = Some \"Queeg.txt\"; Format = SameLine; Season = 2; Episode = 5 };\n    { Id = \"tt0684169\"; Transcript = Some \"Paralle.txt\"; Format = SameLine; Season = 2; Episode = 6 };\n    { Id = \"tt0684144\"; Transcript = Some \"Backward.txt\"; Format = SameLine; Season = 3; Episode = 1 };\n    { Id = \"tt0767232\"; Transcript = Some \"Marooned.txt\"; Format = SameLine; Season = 3; Episode = 2 };\n    { Id = \"tt0684172\"; Transcript = Some \"Polymorp.txt\"; Format = SameLine; Season = 3; Episode = 3 };\n    { Id = \"tt0684148\"; Transcript = Some \"Bodyswap.txt\"; Format = SameLine; Season = 3; Episode = 4 };\n    { Id = \"tt0684185\"; Transcript = Some \"Timeslid.txt\"; Format = SameLine; Season = 3; Episode = 5 };\n    { Id = \"tt0684183\"; Transcript = Some \"Thelastd.txt\"; Format = SameLine; Season = 3; Episode = 6 };\n    { Id = \"tt0684149\"; Transcript = Some \"Camille.txt\"; Format = SameLine; Season = 4; Episode = 1 };\n    { Id = \"tt0684152\"; Transcript = Some \"Dna.txt\"; Format = SameLine; Season = 4; Episode = 2 };\n    { Id = \"tt0684160\"; Transcript = Some \"Justice.txt\"; Format = SameLine; Season = 4; Episode = 3 };\n    { Id = \"tt0684187\"; Transcript = Some \"Whitehol.txt\"; Format = SameLine; Season = 4; Episode = 4 };\n    { Id = \"tt0684153\"; Transcript = Some \"Dimensio.txt\"; Format = SameLine; Season = 4; Episode = 5 };\n    { Id = \"tt0684164\"; Transcript = Some \"Meltdown.txt\"; Format = SameLine; Season = 4; Episode = 6 };\n    { Id = \"tt0684159\"; Transcript = Some \"Holoship.txt\"; Format = SameLine; Season = 5; Episode = 1 };\n    { Id = \"tt0684182\"; Transcript = Some \"Inquisit.txt\"; Format = SameLine; Season = 5; Episode = 2 };\n    { Id = \"tt0684179\"; Transcript = Some \"Terrorfo.txt\"; Format = SameLine; Season = 5; Episode = 3 };\n    { Id = \"tt0684174\"; Transcript = Some \"Quarinti.txt\"; Format = SameLine; Season = 5; Episode = 4 };\n    { Id = \"tt0756588\"; Transcript = Some \"Demonsan.txt\"; Format = SameLine; Season = 5; Episode = 5 };\n    { Id = \"tt0684143\"; Transcript = Some \"Backtore.txt\"; Format = SameLine; Season = 5; Episode = 6 };\n    { Id = \"tt0684173\"; Transcript = Some \"Psirens.txt\"; Format = SameLine; Season = 6; Episode = 1 };\n    { Id = \"tt0684163\"; Transcript = Some \"Legion.txt\"; Format = SameLine; Season = 6; Episode = 2 };\n    { Id = \"tt0684158\"; Transcript = Some \"Gunmen.txt\"; Format = SameLine; Season = 6; Episode = 3 };\n    { Id = \"tt0684155\"; Transcript = Some \"Emohawk.txt\"; Format = SameLine; Season = 6; Episode = 4 };\n    { Id = \"tt0684176\"; Transcript = Some \"Rimmerwo.txt\"; Format = SameLine; Season = 6; Episode = 5 };\n    { Id = \"tt0756589\"; Transcript = Some \"Outoftim.txt\"; Format = SameLine; Season = 6; Episode = 6 };\n    { Id = \"tt0684184\"; Transcript = Some \"tikka.txt\"; Format = NextLine; Season = 7; Episode = 1 };\n    { Id = \"tt0684178\"; Transcript = Some \"stoak.txt\"; Format = NextLineDoubleSpaced; Season = 7; Episode = 2 };\n    { Id = \"tt0684168\"; Transcript = Some \"ouroboros.txt\"; Format = NextLine; Season = 7; Episode = 3 };\n    { Id = \"tt0684154\"; Transcript = Some \"ductsoup.txt\"; Format = NextLine; Season = 7; Episode = 4 };\n    { Id = \"tt0756587\"; Transcript = Some \"blue.txt\"; Format = NextLineDoubleSpaced; Season = 7; Episode = 5 };\n    { Id = \"tt0684147\"; Transcript = Some \"beyond.txt\"; Format = NextLineDoubleSpaced; Season = 7; Episode = 6 };\n    { Id = \"tt0684156\"; Transcript = Some \"epideme.txt\"; Format = NextLineDoubleSpaced; Season = 7; Episode = 7 };\n    { Id = \"tt0684166\"; Transcript = Some \"nanarchy.txt\"; Format = NextLineDoubleSpaced; Season = 7; Episode = 8 };\n    { Id = \"tt0684140\"; Transcript = Some \"bir1.txt\"; Format = NextLine; Season = 8; Episode = 1 };\n    { Id = \"tt0684141\"; Transcript = Some \"bir2.txt\"; Format = NextLine; Season = 8; Episode = 2 };\n    { Id = \"tt0684142\"; Transcript = None; Format = NextLine; Season = 8; Episode = 3 };\n    { Id = \"tt0684150\"; Transcript = Some \"cassandra.txt\"; Format = NextLine; Season = 8; Episode = 4 };\n    { Id = \"tt0684162\"; Transcript = Some \"krytietv.txt\"; Format = NextLine; Season = 8; Episode = 5 };\n    { Id = \"tt0684170\"; Transcript = Some \"pete1.txt\"; Format = NextLine; Season = 8; Episode = 6 };\n    { Id = \"tt0684171\"; Transcript = Some \"pete2.txt\"; Format = NextLine; Season = 8; Episode = 7 };\n    { Id = \"tt0684167\"; Transcript = Some \"otg.txt\"; Format = NextLine; Season = 8; Episode = 8 };\n    { Id = \"tt1365540\"; Transcript = None; Format = NextLine; Season = 9; Episode = 1 };\n    { Id = \"tt1371606\"; Transcript = None; Format = NextLine; Season = 9; Episode = 2 };\n    { Id = \"tt1400975\"; Transcript = None; Format = NextLine; Season = 9; Episode = 3 };\n    { Id = \"tt1997038\"; Transcript = None; Format = NextLine; Season = 10; Episode = 1 };\n    { Id = \"tt1999714\"; Transcript = None; Format = NextLine; Season = 10; Episode = 2 };\n    { Id = \"tt1999715\"; Transcript = None; Format = NextLine; Season = 10; Episode = 3 };\n    { Id = \"tt1999716\"; Transcript = None; Format = NextLine; Season = 10; Episode = 4 };\n    { Id = \"tt1999717\"; Transcript = None; Format = NextLine; Season = 10; Episode = 5 };\n    { Id = \"tt1999718\"; Transcript = None; Format = NextLine; Season = 10; Episode = 6 };\n    { Id = \"tt5218244\"; Transcript = None; Format = NextLine; Season = 11; Episode = 1 };\n    { Id = \"tt5218254\"; Transcript = None; Format = NextLine; Season = 11; Episode = 2 };\n    { Id = \"tt5218266\"; Transcript = None; Format = NextLine; Season = 11; Episode = 3 };\n    { Id = \"tt5218284\"; Transcript = None; Format = NextLine; Season = 11; Episode = 4 };\n    { Id = \"tt5218308\"; Transcript = None; Format = NextLine; Season = 11; Episode = 5 };\n    { Id = \"tt5218316\"; Transcript = None; Format = NextLine; Season = 11; Episode = 6 }\n]", "outputs": [], "metadata": {"collapsed": true}}, {"source": "These transcripts were then parsed to remove scene description, production notes, accentuations and other irrelevant information and to attribute each of the remaining lines to one of the five main characters of Red Dwarf: ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": "type Character =\n| Lister\n| Rimmer\n| Cat\n| Kryten\n| Holly\n\nlet characterName character =\n    match character with\n    | Lister -> \"LISTER\"\n    | Rimmer -> \"RIMMER\"\n    | Cat -> \"CAT\"\n    | Kryten -> \"KRYTEN\"\n    | Holly -> \"HOLLY\"", "outputs": [], "metadata": {"collapsed": true}}, {"source": "This presented several challenges as the transcripts were in a number of formats (text on the same line as the character name, text on the line after the character name, text on the line after the character name but each line double spaced).\n\nTo first format \"SameLine\" looks as follows:\n\n```\nRIMMER: Is that a cigarette you're smoking, Lister?\nLISTER: No, it's a chicken.\nRIMMER: Right!  You're on report.  Two times in as many minutes, Lister!\n  I don't know.\n```\n\nThis format contains speech on the same line as the character name with extended speech wrapped onto subsequent lines and indented by two spaces. To read this format, a ```SameLineScanner``` type was defined that joins lines of speech such that it could be easily used by the ```Seq.scan``` function a successfully parse a sequence of strings representing text from the episode. The ```SameLineScanner``` is shown below:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 9, "cell_type": "code", "source": "type SameLineScanner = {\n    LineBuilder : string\n    Lines : string seq\n} with\n    static member Empty = { LineBuilder = \"\"; Lines = [] }\n    static member Scan scanner (line : string) =\n        match line.StartsWith(\"  \") with\n        | true -> \n            let result = sprintf \"%s %s\" scanner.LineBuilder (line.Trim())\n            { scanner with LineBuilder = result; Lines = [] }\n        | false -> \n            { scanner with LineBuilder = line; Lines = [ scanner.LineBuilder ]}\n\nlet parseSameLine (lines : string seq) =\n    lines\n    |> Seq.append (Seq.singleton \"\")\n    |> Seq.scan SameLineScanner.Scan SameLineScanner.Empty\n    |> Seq.collect (fun s -> s.Lines )\n    |> Seq.map (fun l -> Regex.Replace(l, \"\\(.*?\\)\", \"\").Replace(\"_\", \"\").Replace(\"*\", \"\").Replace(\"  \", \" \").Replace('\"', '\\'').Trim())\n    |> Seq.where (fun l -> not (String.IsNullOrWhiteSpace(l)))", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The other two formats - 'NextLine' and 'NextLineDoubleSpaced' - look like this:\n\n```\nRIMMER\n  \"Dear Mister Lister, your appeal has been successful\"!\n  \"From this day forth all inmates with no record of violence or depression\nwill be allowed... to have strings on their guitars\"...\n  This appeal was all about guitar strings?\n\nLISTER\n  You didn't think it was about getting out of here, did you?\n\nRIMMER\n  You mean to say I've been busting my balls so you can have strings on your\nlousy, stinking guitar??\n\nLISTER\n  You've been a brick, man. And as a personal 'thank you', I thought I'd\nwrite you a song...\n```\n\nWith 'NextLineDoubleSpaced' being just that - an additional empty line between each line of the transcript. In order to process these transcripts a similar approach was employed as with the 'SameLine' format, namely a ```NextLineScanner``` was written that used character names and blank lines to delimit the speech of each character:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 10, "cell_type": "code", "source": "type NextLineScanner = {\n    ReadingCharacter : Character option\n    Spacing : int\n    CurrentSpacing : int\n    LineBuilder : string\n    Lines : string seq\n} with\n    static member For spacing = { ReadingCharacter = None; Spacing = spacing; CurrentSpacing = 0; LineBuilder = \"\"; Lines = [] }\n    static member Scan scanner (line : string) =\n        match (line.ToUpper()) with\n        | \"LISTER\" -> { scanner with ReadingCharacter = Some Lister; CurrentSpacing = 0; LineBuilder = \"\"; Lines = [ ] }\n        | \"RIMMER\" -> { scanner with ReadingCharacter = Some Rimmer; CurrentSpacing = 0; LineBuilder = \"\"; Lines = [ ] }\n        | \"CAT\" -> { scanner with ReadingCharacter = Some Cat; CurrentSpacing = 0; LineBuilder = \"\"; Lines = [ ] }\n        | \"KRYTEN\" -> { scanner with ReadingCharacter = Some Kryten; CurrentSpacing = 0; LineBuilder = \"\"; Lines = [ ] }\n        | \"HOLLY\" -> { scanner with ReadingCharacter = Some Holly; CurrentSpacing = 0; LineBuilder = \"\"; Lines = [ ] }\n        | _ ->\n            match scanner.ReadingCharacter, String.IsNullOrWhiteSpace(line) with\n            | Some character, false -> { scanner with LineBuilder = (sprintf \"%s %s\" scanner.LineBuilder (line.Trim())); CurrentSpacing = 0; Lines = [] }\n            | Some character, true when scanner.CurrentSpacing < scanner.Spacing ->  { scanner with CurrentSpacing = scanner.CurrentSpacing + 1; Lines = [] }\n            | Some character, true -> { scanner with ReadingCharacter = None; CurrentSpacing = 0; LineBuilder = \"\"; Lines = [ (sprintf \"%s: %s\" (characterName character) scanner.LineBuilder) ] }\n            | _, _ -> { scanner with ReadingCharacter = None; LineBuilder = \"\"; Lines = [ ] }\n\nlet parseNextLine (lines : string seq) spacing =\n    lines\n    |> Seq.append (Seq.singleton \"\")\n    |> Seq.scan NextLineScanner.Scan (NextLineScanner.For spacing)\n    |> Seq.collect (fun s -> s.Lines )\n    |> Seq.map (fun l -> Regex.Replace(l, \"\\(.*?\\)\", \"\").Replace(\"_\", \"\").Replace(\"*\", \"\").Replace(\"  \", \" \").Replace('\"', '\\'').Trim())\n    |> Seq.where (fun l -> not (String.IsNullOrWhiteSpace(l)))", "outputs": [], "metadata": {"collapsed": false}}, {"source": "These two 'scanners' were then used to parse valid lines from all episodes into a common (SameLine) format:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": "let transcripts = \"https://github.com/ibebbs/RedDwarfAnalysis/tree/master/Transcript\"\n\nlet episodeLines =\n    episodeSources\n    |> Seq.where (fun s -> s.Transcript.IsSome)\n    |> Seq.map (fun s -> (s.Season, s.Episode, s.Format, (File.ReadAllLines(Path.Combine(transcripts, s.Transcript.Value)))))\n    |> Seq.collect (fun (season, episode, format, lines) -> \n        let parsedLines =\n            match format with\n            | SameLine -> parseSameLine lines\n            | NextLine -> parseNextLine lines 0\n            | NextLineDoubleSpaced -> parseNextLine lines 1\n        parsedLines\n        |> Seq.map (fun line -> (season, episode, line)))", "outputs": [], "metadata": {"collapsed": false}}, {"source": "[Active patterns](https://docs.microsoft.com/en-us/dotnet/articles/fsharp/language-reference/active-patterns) were then used to associate each line with a character:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 13, "cell_type": "code", "source": "let (|IsLister|_|) (line : string) =\n    match line.ToUpper().StartsWith(\"LISTER:\") with\n    | true when line.Length > 8 -> Some (line.Substring(8))\n    | _ -> None\n    \nlet (|IsKryten|_|) (line : string) =\n    match line.ToUpper().StartsWith(\"KRYTEN:\") with\n    | true when line.Length > 8 -> Some (line.Substring(8))\n    | _ -> None\n\nlet (|IsRimmer|_|) (line : string) =\n    match line.ToUpper().StartsWith(\"RIMMER:\") with\n    | true when line.Length > 8 -> Some (line.Substring(8))\n    | _ -> None\n\nlet (|IsCat|_|) (line : string) =\n    match line.ToUpper().StartsWith(\"CAT:\") with\n    | true when line.Length > 5 -> Some (line.Substring(5))\n    | _ -> None\n\nlet (|IsHolly|_|) (line : string) =\n    match line.ToUpper().StartsWith(\"HOLLY:\") with\n    | true when line.Length > 7 -> Some (line.Substring(7))\n    | _ -> None\n\nlet characterLine line =\n    match line with\n    | IsLister line -> Some (Lister, line)\n    | IsRimmer line -> Some (Rimmer, line)\n    | IsCat line -> Some (Cat, line)\n    | IsKryten line -> Some (Kryten, line)\n    | IsHolly line -> Some (Holly, line)\n    | _ -> None\n\nlet characterLines = \n    episodeLines\n    |> Seq.choose (fun (season, episode, line) ->\n        let result = characterLine line\n        match result with\n        | Some (character, line) -> Some (season, episode, character, line)\n        | None -> None)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "For each line that was successfully associated with a character, a call was made to CoreNLP (hosted in a local container) to calculate sentiment for the line:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 17, "cell_type": "code", "source": "type SentimentResponse = JsonProvider<\"https://raw.githubusercontent.com/ibebbs/RedDwarfAnalysis/master/SentimentResponse.json\">\n\nlet lineSentiment (line : string) =    \n    printfn \"Getting sentiment for line: %s\" line\n    let response = \n        Http.RequestString ( \n            \"http://xi:9000/?properties={\\\"annotators\\\": \\\"tokenize,ssplit,sentiment\\\", \\\"date\\\": \\\"2017-04-02T15:13:00\\\", \\\"outputFormat\\\": \\\"json\\\"}&pipelineLanguage=en\",\n            headers = [ \"Content-Type\", \"text/plain;;charset=UTF-8\" ],\n            httpMethod = \"POST\", \n            body = TextRequest line)\n    let result = SentimentResponse.Parse(response);\n    result.Sentences |> Seq.averageBy (fun s -> float (s.SentimentValue - 2))\n\nlet sentimentLines =\n    characterLines\n    |> Seq.where (fun (season, episode, character, line) -> not (String.IsNullOrWhiteSpace(line)))\n    |> Seq.map (fun (season, episode, character, line) -> \n        let sentiment = lineSentiment line\n        (season, episode, character, line, sentiment))", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Finally, the resulting data was saved to a CSV for analysis (disabled for Jupyter):", "cell_type": "markdown", "metadata": {}}, {"execution_count": 18, "cell_type": "code", "source": "let sentimentCsv =\n    sentimentLines\n    |> Seq.map (fun (season, episode, character, line, sentiment) -> sprintf \"%i,%i,%s,%f,\\\"%s\\\"\" season episode (characterName character) sentiment line)\n    \n//File.WriteAllLines(Path.Combine(location, \"Sentiment.csv\"), sentimentCsv)", "outputs": [{"output_type": "stream", "name": "stderr", "text": "/home/nbuser/input.fsx(5,33): error FS0039: The value or constructor 'location' is not defined"}], "metadata": {"collapsed": false}}, {"source": "## Analysis\n\nWith sentiment calculated for all valid lines for all episodes, we could start performing some analysis on the data. To load the data, I used [FSharp.Data's CsvProvider](http://fsharp.github.io/FSharp.Data/library/CsvProvider.html) to parse the CSV created in the previous steps into an easily manipulatable record:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "type SentimentType = CsvProvider<\"https://raw.githubusercontent.com/ibebbs/RedDwarfAnalysis/master/Sentiment.csv\", Schema = \"Season,Episode,Character,Sentiment (float),Line (string)\">\nlet sentiment= SentimentType.Load(\"https://raw.githubusercontent.com/ibebbs/RedDwarfAnalysis/master/Sentiment.csv\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "To start with, I thought it might be good if we can visually see if there are any obvious changes in average episode sentiments across the seasons.\n\n_Note how we force the ordering of characters in the chart. This is done to ensure Lister (who is the only character to have been in every episode) is first, thereby ensuring correct ordering of episodes. If this isn't done, then the chart can be seen to 'double back' on itself when characters miss episodes_", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 17, "cell_type": "code", "source": "let characterOrder =\n    [\"LISTER\"; \"RIMMER\"; \"CAT\"; \"KRYTEN\"; \"HOLLY\" ]\n    |> Seq.mapi (fun index character -> (character, index))\n    |> Map.ofSeq\n\nlet options = \n  Options(\n    pointSize=3,  \n    trendlines=[|\n      Trendline(opacity=0.5,lineWidth=5);\n      Trendline(opacity=0.5,lineWidth=5);\n      Trendline(opacity=0.5,lineWidth=5);\n      Trendline(opacity=0.5,lineWidth=5);\n      Trendline(opacity=0.5,lineWidth=5)|],     \n    hAxis=Axis(title=\"Episode\"),\n    vAxis=Axis(title=\"Sentiment\", format = \"0.00\"))\n\nsentiment.Rows\n|> Seq.groupBy (fun s -> s.Character)\n|> Seq.sortBy (fun (character, lines) -> characterOrder.[character])\n|> Seq.map (fun (character, lines) -> \n    lines \n    |> Seq.groupBy(fun l -> sprintf \"S%sE%s\" (l.Season.ToString(\"00\")) (l.Episode.ToString(\"00\"))) \n    |> Seq.map (fun (episode, l) -> (episode, l |> Seq.averageBy(fun l -> (l.Sentiment + 1.0) / 2.0)))\n    |> Seq.sortBy (fun (episode, sentiment) -> episode))\n|> Chart.Line\n|> Chart.WithOptions (options)\n|> Chart.WithLabels [\"LISTER\"; \"RIMMER\"; \"CAT\"; \"KRYTEN\"; \"HOLLY\"]\n|> Chart.WithTitle \"Character Average Sentiment Per Episode\"", "outputs": [{"execution_count": 17, "output_type": "execute_result", "data": {"text/html": "<script type=\"text/javascript\">\r\n    google.load('visualization', '1.0', { packages: ['corechart'], callback: drawChart })\r\n            function drawChart() {\r\n                var data = new google.visualization.DataTable({\"cols\": [{\"type\": \"string\" ,\"id\": \"Column 1\" ,\"label\": \"Column 1\" }, {\"type\": \"number\" ,\"id\": \"LISTER\" ,\"label\": \"LISTER\" }, {\"type\": \"number\" ,\"id\": \"RIMMER\" ,\"label\": \"RIMMER\" }, {\"type\": \"number\" ,\"id\": \"CAT\" ,\"label\": \"CAT\" }, {\"type\": \"number\" ,\"id\": \"KRYTEN\" ,\"label\": \"KRYTEN\" }, {\"type\": \"number\" ,\"id\": \"HOLLY\" ,\"label\": \"HOLLY\" }], \"rows\" : [{\"c\" : [{\"v\": \"S01E01\"}, {\"v\": 0.410981914728682}, {\"v\": 0.404492969879518}, {\"v\": 0.549159678571429}, {}, {\"v\": 0.346264362068965}]}, {\"c\" : [{\"v\": \"S01E02\"}, {\"v\": 0.386165581699346}, {\"v\": 0.403048788617886}, {\"v\": 0.430288461538462}, {}, {\"v\": 0.365931367647059}]}, {\"c\" : [{\"v\": \"S01E03\"}, {\"v\": 0.379435483870968}, {\"v\": 0.41878177852349}, {\"v\": 0.510601557692308}, {}, {\"v\": 0.4875}]}, {\"c\" : [{\"v\": \"S01E04\"}, {\"v\": 0.420161290322581}, {\"v\": 0.435544219387755}, {\"v\": 0.565628807692308}, {}, {\"v\": 0.425}]}, {\"c\" : [{\"v\": \"S01E05\"}, {\"v\": 0.421259842519685}, {\"v\": 0.384644004807692}, {\"v\": 0.363372363636364}, {}, {\"v\": 0.295698919354839}]}, {\"c\" : [{\"v\": \"S01E06\"}, {\"v\": 0.426392258474576}, {\"v\": 0.38094175}, {\"v\": 0.618290066666667}, {}, {\"v\": 0.331159413043478}]}, {\"c\" : [{\"v\": \"S02E01\"}, {\"v\": 0.39086879787234}, {\"v\": 0.414147284883721}, {\"v\": 0.5761905}, {\"v\": 0.400276348214286}, {\"v\": 0.333333326923077}]}, {\"c\" : [{\"v\": \"S02E02\"}, {\"v\": 0.433712119318182}, {\"v\": 0.405543887254902}, {\"v\": 0.43333334}, {}, {\"v\": 0.520833333333333}]}, {\"c\" : [{\"v\": \"S02E03\"}, {\"v\": 0.487247481060606}, {\"v\": 0.456963189320388}, {\"v\": 0.35333334}, {}, {\"v\": 0.416666675}]}, {\"c\" : [{\"v\": \"S02E04\"}, {\"v\": 0.413308081818182}, {\"v\": 0.39751585915493}, {\"v\": 0.474264705882353}, {}, {\"v\": 0.394444466666667}]}, {\"c\" : [{\"v\": \"S02E05\"}, {\"v\": 0.456970734939759}, {\"v\": 0.399971648809524}, {\"v\": 0.435049044117647}, {}, {\"v\": 0.452873563218391}]}, {\"c\" : [{\"v\": \"S02E06\"}, {\"v\": 0.432189539215686}, {\"v\": 0.44335715}, {\"v\": 0.461111116666667}, {}, {\"v\": 0.404279283783784}]}, {\"c\" : [{\"v\": \"S03E01\"}, {\"v\": 0.37873932051282}, {\"v\": 0.4375}, {\"v\": 0.455357142857143}, {\"v\": 0.434259255555556}, {\"v\": 0.333333333333333}]}, {\"c\" : [{\"v\": \"S03E02\"}, {\"v\": 0.407643274336283}, {\"v\": 0.392192466666667}, {\"v\": 0.40625}, {\"v\": 0.25}, {\"v\": 0.277777722222222}]}, {\"c\" : [{\"v\": \"S03E03\"}, {\"v\": 0.36799998}, {\"v\": 0.450630257352941}, {\"v\": 0.428947368421053}, {\"v\": 0.3125}, {\"v\": 0.397435884615385}]}, {\"c\" : [{\"v\": \"S03E04\"}, {\"v\": 0.36257440625}, {\"v\": 0.356035725}, {\"v\": 0.421130946428571}, {\"v\": 0.311728407407407}, {\"v\": 0.534090909090909}]}, {\"c\" : [{\"v\": \"S03E05\"}, {\"v\": 0.452561791139241}, {\"v\": 0.471578591463415}, {\"v\": 0.511363636363636}, {\"v\": 0.45833334375}, {\"v\": 0.261904761904762}]}, {\"c\" : [{\"v\": \"S03E06\"}, {\"v\": 0.369002975}, {\"v\": 0.339627911764706}, {\"v\": 0.54666666}, {\"v\": 0.370815759493671}, {\"v\": 0.388888875}]}, {\"c\" : [{\"v\": \"S04E01\"}, {\"v\": 0.477099868055555}, {\"v\": 0.402544333333333}, {\"v\": 0.53395062962963}, {\"v\": 0.389215093220339}, {\"v\": 0.361111083333333}]}, {\"c\" : [{\"v\": \"S04E02\"}, {\"v\": 0.427518313186813}, {\"v\": 0.292013885416667}, {\"v\": 0.423148144444444}, {\"v\": 0.419541225609756}, {\"v\": 0.513888875}]}, {\"c\" : [{\"v\": \"S04E03\"}, {\"v\": 0.37439815}, {\"v\": 0.42316667}, {\"v\": 0.398387096774194}, {\"v\": 0.311255418181818}, {\"v\": 0.356944416666667}]}, {\"c\" : [{\"v\": \"S04E04\"}, {\"v\": 0.362461572463768}, {\"v\": 0.385606064935065}, {\"v\": 0.401620375}, {\"v\": 0.30326577027027}, {\"v\": 0.423913043478261}]}, {\"c\" : [{\"v\": \"S04E05\"}, {\"v\": 0.352483586206897}, {\"v\": 0.452267147058824}, {\"v\": 0.533424923076923}, {\"v\": 0.347701155172414}, {\"v\": 0.2395833125}]}, {\"c\" : [{\"v\": \"S04E06\"}, {\"v\": 0.424413154929577}, {\"v\": 0.333348398734177}, {\"v\": 0.440476185714286}, {\"v\": 0.364242427272727}, {\"v\": 0.541666625}]}, {\"c\" : [{\"v\": \"S05E01\"}, {\"v\": 0.368872544117647}, {\"v\": 0.375627241935484}, {\"v\": 0.45}, {\"v\": 0.322619047619048}, {\"v\": 0.15}]}, {\"c\" : [{\"v\": \"S05E02\"}, {\"v\": 0.475408495098039}, {\"v\": 0.379036012195122}, {\"v\": 0.5635965}, {\"v\": 0.343888893333333}, {\"v\": 0.340277791666667}]}, {\"c\" : [{\"v\": \"S05E03\"}, {\"v\": 0.466428571428571}, {\"v\": 0.3129845}, {\"v\": 0.50390625}, {\"v\": 0.321805558333333}, {\"v\": 0.253787863636364}]}, {\"c\" : [{\"v\": \"S05E04\"}, {\"v\": 0.380666673333333}, {\"v\": 0.294047619047619}, {\"v\": 0.394230769230769}, {\"v\": 0.335789473684211}, {\"v\": 0.0625}]}, {\"c\" : [{\"v\": \"S05E05\"}, {\"v\": 0.486345379518072}, {\"v\": 0.353632474358974}, {\"v\": 0.38186275}, {\"v\": 0.312646009433962}, {\"v\": 0.279762}]}, {\"c\" : [{\"v\": \"S05E06\"}, {\"v\": 0.413255350877193}, {\"v\": 0.424074074074074}, {\"v\": 0.428571404761905}, {\"v\": 0.383152173913043}, {\"v\": 0.48958334375}]}, {\"c\" : [{\"v\": \"S06E01\"}, {\"v\": 0.409042553191489}, {\"v\": 0.410108949152542}, {\"v\": 0.400219302631579}, {\"v\": 0.328508768421053}, {}]}, {\"c\" : [{\"v\": \"S06E02\"}, {\"v\": 0.436723169491525}, {\"v\": 0.364610434782609}, {\"v\": 0.346846851351351}, {\"v\": 0.399999993506494}, {}]}, {\"c\" : [{\"v\": \"S06E03\"}, {\"v\": 0.35229166875}, {\"v\": 0.35188679245283}, {\"v\": 0.368421052631579}, {\"v\": 0.337727272727273}, {}]}, {\"c\" : [{\"v\": \"S06E04\"}, {\"v\": 0.427222213333333}, {\"v\": 0.279166666666667}, {\"v\": 0.348958328125}, {\"v\": 0.311073061643836}, {}]}, {\"c\" : [{\"v\": \"S06E06\"}, {\"v\": 0.449186987804878}, {\"v\": 0.471938775510204}, {\"v\": 0.461538461538462}, {\"v\": 0.444444447619048}, {}]}, {\"c\" : [{\"v\": \"S07E01\"}, {\"v\": 0.421686753012048}, {\"v\": 0.481944444444445}, {\"v\": 0.435483870967742}, {\"v\": 0.229861116666667}, {}]}, {\"c\" : [{\"v\": \"S07E02\"}, {\"v\": 0.417559525}, {\"v\": 0.291013068627451}, {\"v\": 0.602564115384615}, {\"v\": 0.20333334}, {}]}, {\"c\" : [{\"v\": \"S07E03\"}, {\"v\": 0.434010845528455}, {\"v\": 0.198901115384615}, {\"v\": 0.4375}, {\"v\": 0.375716844086021}, {}]}, {\"c\" : [{\"v\": \"S07E04\"}, {\"v\": 0.399524953125}, {}, {\"v\": 0.425816990196078}, {\"v\": 0.310035838709677}, {}]}, {\"c\" : [{\"v\": \"S07E05\"}, {\"v\": 0.37856089380531}, {\"v\": 0.530448711538462}, {\"v\": 0.411781603448276}, {\"v\": 0.297727272727273}, {}]}, {\"c\" : [{\"v\": \"S07E06\"}, {\"v\": 0.388719506097561}, {}, {\"v\": 0.408552631578947}, {\"v\": 0.350915753846154}, {}]}, {\"c\" : [{\"v\": \"S07E07\"}, {\"v\": 0.433423913043478}, {}, {\"v\": 0.410493833333333}, {\"v\": 0.361274505882353}, {}]}, {\"c\" : [{\"v\": \"S07E08\"}, {\"v\": 0.453236247572816}, {}, {\"v\": 0.39369658974359}, {\"v\": 0.380512698924731}, {\"v\": 0.312121181818182}]}, {\"c\" : [{\"v\": \"S08E01\"}, {\"v\": 0.410313920289855}, {\"v\": 0.41125}, {\"v\": 0.424242409090909}, {\"v\": 0.328787878787879}, {\"v\": 0.404411764705882}]}, {\"c\" : [{\"v\": \"S08E02\"}, {\"v\": 0.438034179487179}, {\"v\": 0.317016794117647}, {\"v\": 0.388888916666667}, {\"v\": 0.364516112903226}, {\"v\": 0.5}]}, {\"c\" : [{\"v\": \"S08E04\"}, {\"v\": 0.356763282608696}, {\"v\": 0.367886176829268}, {\"v\": 0.5}, {\"v\": 0.482142857142857}, {\"v\": 0.305555555555556}]}, {\"c\" : [{\"v\": \"S08E05\"}, {\"v\": 0.397400109195402}, {\"v\": 0.316666656862745}, {\"v\": 0.428571428571429}, {\"v\": 0.436687650943396}, {\"v\": 0.4}]}, {\"c\" : [{\"v\": \"S08E06\"}, {\"v\": 0.335227272727273}, {\"v\": 0.199275369565217}, {\"v\": 0.5104166875}, {\"v\": 0.3}, {}]}, {\"c\" : [{\"v\": \"S08E07\"}, {\"v\": 0.338178302325581}, {\"v\": 0.325268822580645}, {\"v\": 0.339743576923077}, {\"v\": 0.268518518518519}, {\"v\": 0.5}]}, {\"c\" : [{\"v\": \"S08E08\"}, {\"v\": 0.462121196969697}, {\"v\": 0.397635141891892}, {\"v\": 0.311838611111111}, {\"v\": 0.452173913043478}, {\"v\": 0.385416625}]}]});\r\n\r\n                var options = {\"hAxis\":{\"title\":\"Episode\"},\"legend\":{\"position\":\"right\"},\"pointSize\":3,\"title\":\"Character Average Sentiment Per Episode\",\"vAxis\":{\"format\":\"0.00\",\"title\":\"Sentiment\"},\"trendlines\":[{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5}]} \r\n\r\n                var chart = new google.visualization.LineChart(document.getElementById('70e03f33-fbf2-4d0c-a74b-cfeb4ba28aca'));\r\n                chart.draw(data, options);\r\n            }\r\n<\/script>\r\n<div id=\"70e03f33-fbf2-4d0c-a74b-cfeb4ba28aca\" style=\"width: 900px; height: 500px;\"><\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "As can be seen, apart from Holly getting a little jaded towards the end of series 5 (Quaranteen - actually a bit of an outlier as she only has a few lines in this episode) there doesn't seem to be any significant trend in changing sentiment. Given we're interested in the change across seasons, how about we look at the average sentiment of each character in each season:", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 18, "cell_type": "code", "source": "sentiment.Rows\n|> Seq.groupBy (fun s -> s.Character)\n|> Seq.sortBy (fun (character, lines) -> characterOrder.[character])\n|> Seq.map (fun (character, lines) -> \n    lines \n    |> Seq.groupBy(fun l -> sprintf \"S%s\" (l.Season.ToString(\"00\"))) \n    |> Seq.map (fun (episode, l) -> (episode, l |> Seq.averageBy(fun l -> (l.Sentiment + 1.0) / 2.0)))\n    |> Seq.sortBy (fun (episode, sentiment) -> episode))\n|> Chart.Line\n|> Chart.WithOptions (options)\n|> Chart.WithLabels [\"LISTER\"; \"RIMMER\"; \"CAT\"; \"KRYTEN\"; \"HOLLY\"]\n|> Chart.WithTitle \"Character Average Sentiment Per Season\"", "outputs": [{"execution_count": 18, "output_type": "execute_result", "data": {"text/html": "<script type=\"text/javascript\">\r\n    google.load('visualization', '1.0', { packages: ['corechart'], callback: drawChart })\r\n            function drawChart() {\r\n                var data = new google.visualization.DataTable({\"cols\": [{\"type\": \"string\" ,\"id\": \"Column 1\" ,\"label\": \"Column 1\" }, {\"type\": \"number\" ,\"id\": \"LISTER\" ,\"label\": \"LISTER\" }, {\"type\": \"number\" ,\"id\": \"RIMMER\" ,\"label\": \"RIMMER\" }, {\"type\": \"number\" ,\"id\": \"CAT\" ,\"label\": \"CAT\" }, {\"type\": \"number\" ,\"id\": \"KRYTEN\" ,\"label\": \"KRYTEN\" }, {\"type\": \"number\" ,\"id\": \"HOLLY\" ,\"label\": \"HOLLY\" }], \"rows\" : [{\"c\" : [{\"v\": \"S01\"}, {\"v\": 0.406534564516129}, {\"v\": 0.404930027653214}, {\"v\": 0.503376355633803}, {}, {\"v\": 0.371463174418605}]}, {\"c\" : [{\"v\": \"S02\"}, {\"v\": 0.438457217741935}, {\"v\": 0.419432365927419}, {\"v\": 0.446628226708075}, {\"v\": 0.400276348214286}, {\"v\": 0.426847293103448}]}, {\"c\" : [{\"v\": \"S03\"}, {\"v\": 0.390402947265625}, {\"v\": 0.409364509574468}, {\"v\": 0.461911485875706}, {\"v\": 0.365938275555556}, {\"v\": 0.3561111}]}, {\"c\" : [{\"v\": \"S04\"}, {\"v\": 0.404741509977827}, {\"v\": 0.381997634048257}, {\"v\": 0.4477619075}, {\"v\": 0.36321342251816}, {\"v\": 0.415345518292683}]}, {\"c\" : [{\"v\": \"S05\"}, {\"v\": 0.44217471496437}, {\"v\": 0.357804234234234}, {\"v\": 0.443172041935484}, {\"v\": 0.33624053638814}, {\"v\": 0.31141346031746}]}, {\"c\" : [{\"v\": \"S06\"}, {\"v\": 0.41352563974359}, {\"v\": 0.37199844137931}, {\"v\": 0.391920474619289}, {\"v\": 0.370267488888889}, {}]}, {\"c\" : [{\"v\": \"S07\"}, {\"v\": 0.415491653795811}, {\"v\": 0.385468630952381}, {\"v\": 0.42657877734375}, {\"v\": 0.33028214059754}, {\"v\": 0.312121181818182}]}, {\"c\" : [{\"v\": \"S08\"}, {\"v\": 0.391580486187845}, {\"v\": 0.35115493880597}, {\"v\": 0.402969018072289}, {\"v\": 0.38637018134715}, {\"v\": 0.388888884615385}]}]});\r\n\r\n                var options = {\"hAxis\":{\"title\":\"Episode\"},\"legend\":{\"position\":\"right\"},\"pointSize\":3,\"title\":\"Character Average Sentiment Per Season\",\"vAxis\":{\"format\":\"0.00\",\"title\":\"Sentiment\"},\"trendlines\":[{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5}]} \r\n\r\n                var chart = new google.visualization.LineChart(document.getElementById('27df6b10-9b63-4b7c-b218-0bd41fed6765'));\r\n                chart.draw(data, options);\r\n            }\r\n<\/script>\r\n<div id=\"27df6b10-9b63-4b7c-b218-0bd41fed6765\" style=\"width: 900px; height: 500px;\"><\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "Well, that's interesting. With the exception of Kryten (and excluding Holly's return) the average sentiment of all the main characters generally trends down over the seasons. I would therefore imagine the season sentiment overall would follow a similar pattern:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 20, "cell_type": "code", "source": "sentiment.Rows\n|> Seq.groupBy(fun l -> sprintf \"S%s\" (l.Season.ToString(\"00\"))) \n|> Seq.map (fun (episode, l) -> (episode, l |> Seq.averageBy(fun l -> (l.Sentiment + 1.0) / 2.0)))\n|> Seq.sortBy (fun (episode, sentiment) -> episode)\n|> Chart.Line\n|> Chart.WithOptions (options)\n|> Chart.WithLabel \"Sentiment\"\n|> Chart.WithTitle \"Average Sentiment Per Season\"", "outputs": [{"execution_count": 20, "output_type": "execute_result", "data": {"text/html": "<script type=\"text/javascript\">\r\n    google.load('visualization', '1.0', { packages: ['corechart'], callback: drawChart })\r\n            function drawChart() {\r\n                var data = new google.visualization.DataTable({\"cols\": [{\"type\": \"string\" ,\"id\": \"Column 1\" ,\"label\": \"Column 1\" }, {\"type\": \"number\" ,\"id\": \"Sentiment\" ,\"label\": \"Sentiment\" }], \"rows\" : [{\"c\" : [{\"v\": \"S01\"}, {\"v\": 0.410314894482366}]}, {\"c\" : [{\"v\": \"S02\"}, {\"v\": 0.429898372795115}]}, {\"c\" : [{\"v\": \"S03\"}, {\"v\": 0.399650723783413}]}, {\"c\" : [{\"v\": \"S04\"}, {\"v\": 0.394102301514154}]}, {\"c\" : [{\"v\": \"S05\"}, {\"v\": 0.385971942293373}]}, {\"c\" : [{\"v\": \"S06\"}, {\"v\": 0.38714603276131}]}, {\"c\" : [{\"v\": \"S07\"}, {\"v\": 0.386195080533024}]}, {\"c\" : [{\"v\": \"S08\"}, {\"v\": 0.378035158596838}]}]});\r\n\r\n                var options = {\"hAxis\":{\"title\":\"Episode\"},\"legend\":{\"position\":\"right\"},\"pointSize\":3,\"title\":\"Average Sentiment Per Season\",\"vAxis\":{\"format\":\"0.00\",\"title\":\"Sentiment\"},\"trendlines\":[{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5}]} \r\n\r\n                var chart = new google.visualization.LineChart(document.getElementById('bc066645-c3c1-4739-a6c8-fb12030a6548'));\r\n                chart.draw(data, options);\r\n            }\r\n<\/script>\r\n<div id=\"bc066645-c3c1-4739-a6c8-fb12030a6548\" style=\"width: 900px; height: 500px;\"><\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "Which quite accurately reflects my opinion of the show's deterioration. Perhaps I no longer appreciate the humour as it has simply become more cynical over the last few seasons?\n\nNote to self: it would have been interesting to record my rating for each show / season prior to starting this investigation which I could then have compared to the above.\n\nTo see if there's any correlation between sentiment and rating, I'm going to pull in the rating parsing code authored for [part 1](https://notebooks.azure.com/n/bSdVlvDz5sI/notebooks/Investigation.ipynb) of this analysis.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 21, "cell_type": "code", "source": "let ratingCategoryNames = [\n  \"Males\";\n  \"Females\";\n  \"Aged under 18\";\n  \"Males under 18\";\n  \"Aged 18-29\";\n  \"Males Aged 18-29\";\n  \"Females Aged 18-29\";\n  \"Aged 30-44\";\n  \"Males Aged 30-44\";\n  \"Females Aged 30-44\";\n  \"Aged 45+\";\n  \"Males Aged 45+\";\n  \"Females Aged 45+\";\n  \"Top 1000 voters\";\n  \"US users\";\n  \"Non-US users\";\n]\n\ntype RatingCategory =\n  | ``Males`` = 0\n  | ``Females`` = 1\n  | ``Aged under 18`` = 2\n  | ``Males under 18`` = 3\n  | ``Aged 18-29`` = 4\n  | ``Males Aged 18-29`` = 5\n  | ``Females Aged 18-29`` = 6\n  | ``Aged 30-44`` = 7\n  | ``Males Aged 30-44`` = 8\n  | ``Females Aged 30-44`` = 9\n  | ``Aged 45`` = 10\n  | ``Males Aged 45`` = 11\n  | ``Females Aged 45`` = 12\n  | ``Top 1000 voters`` = 13\n  | ``US users`` = 14\n  | ``Non-US users`` = 15\n\ntype EpisodeRatings = {\n    Id : string;\n    Category : RatingCategory;\n    Votes : int;\n    Rating : decimal\n}\n\nlet parseCategory c =\n  let index = Seq.tryFindIndex (fun cn -> cn = c) ratingCategoryNames\n  match index with\n  | Some x -> Some (enum<RatingCategory>(x))\n  | None -> None\n\nlet parseRatings id =\n  let title (node : HtmlNode) =\n      node.Descendants[\"a\"]\n      |> Seq.map (fun d -> d.InnerText())\n  \n  let votes (node : HtmlNode) =\n      [ node.InnerText() ]\n  \n  let rating (node : HtmlNode) =\n      [ node.InnerText() ]\n  let document = HtmlDocument.Load(\"https://raw.githubusercontent.com/ibebbs/RedDwarfAnalysis/master/Ratings/\" + id + \".html\")\n  let content = document.CssSelect(\"#tn15content\").[0]\n  let tables = \n    content.Descendants[\"table\"]\n    |> Seq.toArray\n  let rows =\n    tables.[1].Descendants[\"tr\"]\n    |> Seq.map (fun row -> (row, row.Descendants[\"td\"] |> Seq.toArray))\n    |> Seq.where (fun (row, data) -> data.Length = 3)\n    |> Seq.map (fun (row, data) -> ( (title data.[0]), (votes data.[1]), (rating data.[2])))\n    |> Seq.collect (fun (t, v, r) -> Seq.zip3 t v r)\n    |> Seq.map (fun (t, v, r) -> ((parseCategory t), System.Int32.Parse(v.Trim()), System.Decimal.Parse(r.Trim())))\n    |> Seq.where (fun (t, v, r) -> t.IsSome)\n    |> Seq.map (fun (t, v, r) -> { Id = id; Category = t.Value; Votes = v; Rating = r })\n  rows", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Which allows us to create a comparison chart:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 28, "cell_type": "code", "source": "let ``Average Sentiment Per Season`` = \n    sentiment.Rows\n    |> Seq.groupBy(fun l -> sprintf \"S%s\" (l.Season.ToString(\"00\"))) \n    |> Seq.map (fun (season, l) -> (season, l |> Seq.averageBy(fun l -> (l.Sentiment + 1.0) / 2.0)))\n    |> Seq.sortBy (fun (season, sentiment) -> season)\n    |> Seq.toArray\n\nlet ``Top 1000 voters - Average Rating Per Season`` =\n    episodeSources\n    |> Seq.where (fun s -> s.Transcript.IsSome)\n    |> Seq.collect (fun es -> \n        parseRatings es.Id\n        |> Seq.where (fun r -> r.Category = RatingCategory.``Top 1000 voters``)\n        |> Seq.map (fun r -> (es.Season, es.Episode, (float) r.Rating / 10.0)))\n    |> Seq.groupBy (fun (season, episode, rating) -> sprintf \"S%s\" (season.ToString(\"00\")))\n    |> Seq.map (fun (season, ratings) -> (season, ratings |> Seq.averageBy (fun (season, episode, rating) -> rating)))\n    |> Seq.sortBy (fun (season, rating) -> season)\n    |> Seq.toArray\n\n[``Average Sentiment Per Season``; ``Top 1000 voters - Average Rating Per Season``]\n|> Chart.Line\n|> Chart.WithOptions (options)\n|> Chart.WithLabels [\"Sentiment\"; \"Rating\"]\n|> Chart.WithTitle \"Average Rating vs Average Sentiment Per Season\"", "outputs": [{"execution_count": 28, "output_type": "execute_result", "data": {"text/html": "<script type=\"text/javascript\">\r\n    google.load('visualization', '1.0', { packages: ['corechart'], callback: drawChart })\r\n            function drawChart() {\r\n                var data = new google.visualization.DataTable({\"cols\": [{\"type\": \"string\" ,\"id\": \"Column 1\" ,\"label\": \"Column 1\" }, {\"type\": \"number\" ,\"id\": \"Sentiment\" ,\"label\": \"Sentiment\" }, {\"type\": \"number\" ,\"id\": \"Rating\" ,\"label\": \"Rating\" }], \"rows\" : [{\"c\" : [{\"v\": \"S01\"}, {\"v\": 0.410314894482366}, {\"v\": 0.741666666666667}]}, {\"c\" : [{\"v\": \"S02\"}, {\"v\": 0.429898372795115}, {\"v\": 0.788333333333333}]}, {\"c\" : [{\"v\": \"S03\"}, {\"v\": 0.399650723783413}, {\"v\": 0.796666666666667}]}, {\"c\" : [{\"v\": \"S04\"}, {\"v\": 0.394102301514154}, {\"v\": 0.786666666666667}]}, {\"c\" : [{\"v\": \"S05\"}, {\"v\": 0.385971942293373}, {\"v\": 0.79}]}, {\"c\" : [{\"v\": \"S06\"}, {\"v\": 0.38714603276131}, {\"v\": 0.771666666666667}]}, {\"c\" : [{\"v\": \"S07\"}, {\"v\": 0.386195080533024}, {\"v\": 0.71375}]}, {\"c\" : [{\"v\": \"S08\"}, {\"v\": 0.378035158596838}, {\"v\": 0.694285714285714}]}]});\r\n\r\n                var options = {\"hAxis\":{\"title\":\"Episode\"},\"legend\":{\"position\":\"right\"},\"pointSize\":3,\"title\":\"Average Rating vs Average Sentiment Per Season\",\"vAxis\":{\"format\":\"0.00\",\"title\":\"Sentiment\"},\"trendlines\":[{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5},{\"lineWidth\":5,\"opacity\":0.5}]} \r\n\r\n                var chart = new google.visualization.LineChart(document.getElementById('190f5049-4b6b-4378-93f1-f1c363896920'));\r\n                chart.draw(data, options);\r\n            }\r\n<\/script>\r\n<div id=\"190f5049-4b6b-4378-93f1-f1c363896920\" style=\"width: 900px; height: 500px;\"><\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "Unfortunately, while it seems there may be a correlation, it's quite difficult to see the magnitude of the correlation in this chart. To dig into this further we'll start by mapping sentiment vs rating on a scatter chart:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 31, "cell_type": "code", "source": "``Top 1000 voters - Average Rating Per Season``\n|> Seq.map (fun (season, rating) -> rating)\n|> Seq.zip (``Average Sentiment Per Season`` |> Seq.map (fun (season, sentiment) -> sentiment))\n|> Chart.Scatter\n|> Chart.WithOptions (Options(trendlines = [| Trendline() |], vAxis = Axis(title = \"Rating\"), hAxis = Axis(title = \"Sentiment\")))\n|> Chart.WithTitle \"Sentiment vs Rating\"", "outputs": [{"execution_count": 31, "output_type": "execute_result", "data": {"text/html": "<script type=\"text/javascript\">\r\n    google.load('visualization', '1.0', { packages: ['corechart'], callback: drawChart })\r\n            function drawChart() {\r\n                var data = new google.visualization.DataTable({\"cols\": [{\"type\": \"number\" ,\"id\": \"Column 1\" ,\"label\": \"Column 1\" }, {\"type\": \"number\" ,\"id\": \"Column 2\" ,\"label\": \"Column 2\" }], \"rows\" : [{\"c\" : [{\"v\": 0.410314894482366}, {\"v\": 0.741666666666667}]}, {\"c\" : [{\"v\": 0.429898372795115}, {\"v\": 0.788333333333333}]}, {\"c\" : [{\"v\": 0.399650723783413}, {\"v\": 0.796666666666667}]}, {\"c\" : [{\"v\": 0.394102301514154}, {\"v\": 0.786666666666667}]}, {\"c\" : [{\"v\": 0.385971942293373}, {\"v\": 0.79}]}, {\"c\" : [{\"v\": 0.38714603276131}, {\"v\": 0.771666666666667}]}, {\"c\" : [{\"v\": 0.386195080533024}, {\"v\": 0.71375}]}, {\"c\" : [{\"v\": 0.378035158596838}, {\"v\": 0.694285714285714}]}]});\r\n\r\n                var options = {\"hAxis\":{\"title\":\"Sentiment\"},\"legend\":{\"position\":\"none\"},\"title\":\"Sentiment vs Rating\",\"vAxis\":{\"title\":\"Rating\"},\"trendlines\":[{}]} \r\n\r\n                var chart = new google.visualization.ScatterChart(document.getElementById('899cad92-eef2-4619-a442-51e32cd33fdb'));\r\n                chart.draw(data, options);\r\n            }\r\n<\/script>\r\n<div id=\"899cad92-eef2-4619-a442-51e32cd33fdb\" style=\"width: 900px; height: 500px;\"><\/div>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "As we can see, while there are a couple of interesting groupings, there is a general trend suggesting higher sentiment scores get higher average ratings. This can be quanitied using the [Person correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) which is:\n\n> a measure of the linear correlation between two variables X and Y [and] has a value between +1 and \u00e2\u0088\u00921, where 1 is total positive linear correlation, 0 is no linear correlation, and \u00e2\u0088\u00921 is total negative linear correlation\n\nThe math behind the coefficient is fairly involved but fortunately the [MathNet.Numerics](https://numerics.mathdotnet.com/) library (included as a dependency of the [FsLab](https://fslab.org/) package) provides a function for calculating this value as follows:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 32, "cell_type": "code", "source": "Correlation.Pearson(\n    ``Average Sentiment Per Season`` |> Seq.map (fun (season, sentiment) -> sentiment), \n    ``Top 1000 voters - Average Rating Per Season`` |> Seq.map (fun (season, rating) -> rating)\n)", "outputs": [{"execution_count": 32, "output_type": "execute_result", "data": {"text/plain": "0.438332006"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "Given that a value of 1 would represent a perfect correlation between increased sentiment and increased rating, a value of -1 would represent a perfect correlation between decreased sentiment and increased rating and a value of 0 would represent no correlation at all between sentiment and rating, our calculated value of `0.438332006` represents a reasonable correlation between increased sentiment and increased rating.", "cell_type": "markdown", "metadata": {}}, {"source": "## Conclusion\n\nGiven that, as we saw above, sentiment has generally declined over the seasons and this has been reflected in the ratings, perhaps the conclusion from my first investigation - that I was \"a miserable old git\" - was incorrect and I am actually (as I like to believe) an optimist who simply dislikes cynicism.\n\nIn fact, from the above, it seems it is the crew of Red Dwarf who have become **miserable old gits**.\n\nYes, I like that conclusion much better.", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "F#", "name": "ifsharp", "language": "fsharp"}, "language_info": {"mimetype": "text/x-fsharp", "nbconvert_exporter": "", "version": "4.3.1.0", "name": "fsharp", "file_extension": ".fs", "pygments_lexer": "", "codemirror_mode": ""}, "language": "fsharp"}}